## Metagenomic pan-genome profiling
This script will map metagenomic reads to bacterial pangenomes and quantify these genes in your data
You can either target one or more specific species, or provide this script a species abundance file
The pipeline can be broken down into three main steps:  
  1) build a database of pangenomes for abundance bacterial species  
  2) map metagenomic reads to the database  
  3) use mapped reads to quantify pangenome genes  

## Usage
```
positional arguments:
  outdir                Path to directory to store results. Name should correspond to sample identifier. 

optional arguments:
  -h, --help            show this help message and exit
  --remove_temp         remove intermediate files generated by PhyloCNV. 
                        intermediate files can be useful to quickly rerun parts of pipeline.

Pipeline options (choose one or more; default=all):
  --build_db            Build bowtie2 database of pangenomes
  --align               Align reads to pangenome database
  --call_genes          Compute coverage of genes in pangenome database

Database options (if using --build_db):
  --sp_cov GC_COV       Include species with >X coverage (3.0)
  --sp_topn GC_TOPN     Include top N most abundant species
  --sp_id GC_ID         One or more species identifiers to include in database. Separate ids with a comma

Read alignment options (if using --align):
  -1 M1                 FASTA/FASTQ file containing 1st mate if paired or unpaired reads
  -2 M2                 FASTA/FASTQ file containing 2nd mate if paired
  -s {very-fast,fast,sensitive,very-sensitive}
                        Alignment speed/sensitivity (very-sensitive)
  -n MAX_READS          # reads to use from input file(s) (use all)
  -t THREADS            Number of threads to use

Quantify genes options (if using --call_genes):
  --readq READQ         Discard reads with mean quality < READQ (20)
  --mapid MAPID         Discard reads with alignment identity < MAPID (94.0)
  --mapq MAPQ           Discard reads with mapping quality < MAPQ (10)
  --aln_cov ALN_COV     Discard reads with alignment coverage < ALN_COV (0.75)
  --trim INT            Trim N base-pairs from read-tails (0)
```

## Example

1) run entire pipeline using defaults:  
`run_phylo_cnv.py genes /path/to/outdir -1 /path/to/reads_1.fq.gz -2 /path/to/reads_2.fq.gz`
			
2) run entire pipeline for a specific species:  
`run_phylo_cnv.py genes /path/to/outdir --sp_id 57955 -1 /path/to/reads_1.fq.gz -2 /path/to/reads_2.fq.gz`

3) just align reads, use faster alignment, only use the first 10M reads, use 4 CPUs:  
`run_phylo_cnv.py genes /path/to/outdir --align -1 /path/to/reads_1.fq.gz -2 /path/to/reads_2.fq.gz -s very-fast -n 10000000 -t 4`

4) just quantify genes, keep reads with >=95% alignment identity and reads with an average quality-score >=30: 
`run_phylo_cnv.py snps /path/to/outdir --call_genes --mapid 95 --readq 30`



## Output

The output of this script is a directory with the following files:

* **pangenome.bam** (*intermediate output*): alignments of metagenomic reads versus pangenome database
* **db/** (*intermediate output*): directory that contains local fasta and bowtie2 pangenome 
* **coverage** (*final output*): directory containing gene coverages for each selected species. File names indicate species identifiers.
* **genes_summary_stats.txt** (*final output*): alignment summary statistics for each species
* intermediate outputs can be removed using `--remove`

Example of gene coverage table for one sample (ex: coverage/57955.cov.gz):

| gene_id      | raw_coverage      | normalized_coverage  |
| :----------: |:-------------:| :------------------: |
| 1235786.3.peg.1010         | 6.78        | 0.78              |
| ...           | ...           |   ...               |
| 997891.3.rna.48         | 3.99          |   0.46              |

Field definitions:  

* **gene_id**: gene identifer; `peg` and `rna` indicate coding & non-coding genes respectively
* **raw_coverage**: (number of aligned base-pairs)/(gene length in base-pairs)
* **normalized_coverage**: (raw_coverage of ref_id)/(median raw_coverage of 15 universal-single-copy genes)
  * this is the estimated average copy number of the gene across the population of cells

## Memory usage  
* Memory usage will depend on the number of species you search and the number of reference genomes sequenced per species.
* In practice, peak memory usage will not exceed 1 Gb for most samples

## Speed
* Speed will depend on the number of species you search and the number of reference genomes sequenced per species. 
* For a single species with 1 reference genome, expect ~16,000 reads/second
* Use `-n` and `-t` to increase throughput

## Next step
[Merge results across samples] (https://github.com/snayfach/PhyloCNV/blob/master/docs/merge_cnvs.md)

